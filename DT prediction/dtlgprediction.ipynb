{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "kgexperiment",
   "display_name": "KGExperiment",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RMLTC0010c\n"
     ]
    }
   ],
   "source": [
    "testcaseDir = 'annotations/'\n",
    "testOutput = 'testanno/'\n",
    "json_files = [pos_json for pos_json in os.listdir(testcaseDir) if pos_json.endswith('.json')]\n",
    "\n",
    "# we need both the json and an index number so use enumerate()\n",
    "for index, js in enumerate(json_files):\n",
    "    with open(os.path.join(testcaseDir, js)) as json_file:\n",
    "        #print(json_file)\n",
    "        s = json_file.read()\n",
    "        s = s.replace('\\'','\\\"')\n",
    "        data = json.loads(s)\n",
    "        #data = json.load(json_file)\n",
    "    \n",
    "    fileName = (os.path.splitext(js)[0])\n",
    "    stack=[]\n",
    "    c=0\n",
    "    accessJSON(data) #preprocess the datatype to required format\n",
    "    k,v=seperatekeyvalues(stack)\n",
    "    rows,columns=findingrowscolumns(k)\n",
    "\n",
    "\n",
    "    fileDir = os.path.join(testOutput, fileName+\".csv\")\n",
    " #   print(fileDir,rows,columns)\n",
    "   # print(k, v)\n",
    "    writingintoFile(fileDir, rows, columns, k, v)   #writes datatype modified column to file\n",
    "\n",
    "    flag=0\n",
    "#checking for language tag if any as another json object\n",
    "    stackLG=[]\n",
    "    c=0\n",
    "    accessJSONLT(data)\n",
    "    if(stackLG):\n",
    "        k,v=seperatekeyvalues(stackLG)\n",
    "        rows,columns=findingrowscolumns(k)\n",
    "        fileDir1 = os.path.join(testOutput, fileName+\"_1.csv\")\n",
    "        writingintoFile(fileDir1, rows, columns, k, v)   #writes language tags to another file\n",
    "        flag=1    \n",
    "\n",
    "    if(flag==1):\n",
    "        finalDF=mergeDataset(fileDir,fileDir1)\n",
    "        os.remove(fileDir1)\n",
    "    else:\n",
    "        finalDF = pd.read_csv(fileDir)\n",
    "\n",
    "    finalD = changeLanguagetag(finalDF)\n",
    "\n",
    "    if os.path.exists(fileDir):\n",
    "        os.remove(fileDir)\n",
    "    finalD.to_csv(fileDir, index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accessing nested\n",
    "#1st JSON object\n",
    "def accessJSON(data):\n",
    "    global c\n",
    "    for key,value in data.items():\n",
    "       # print(value)\n",
    "        if(type(value)==type(str())  or type(value)==type(int()) or type(value)==type(float()) or type(value)==type(bool()) ):\n",
    "            stack.append(key)\n",
    "            stack.append(value)\n",
    "            if(key.lower()==\"dt\"):\n",
    "                i=stack.pop()\n",
    "                #print(stack)\n",
    "                if(i.lower()==\"int\" or i.lower() == \"dec\" or i.lower() ==\"str\" or i.lower()==\"bool\" or i.lower() == \"integer\" or i.lower() ==\"decimal\"  or i.lower() ==\"string\" or i.lower()==\"boolean\"):\n",
    "                    if(i.lower()==\"int\" or i.lower()==\"integer\"):\n",
    "                        i=\"xsd:integer\"\n",
    "                    elif(i.lower()==\"dec\" or i.lower() == \"decimal\"):\n",
    "                        i=\"xsd:decimal\"\n",
    "                    elif(i.lower()==\"bool\" or i.lower() == \"boolean\"):\n",
    "                        i=\"xsd:boolean\"\n",
    "                    else:\n",
    "                        i=\"xsd:string\"\n",
    "                elif(re.search(urlRE,i.lower())):\n",
    "                        res = re.findall(r'#',i) \n",
    "                        i=\"xsd:\"+i[(i.index('#')+1):]\n",
    "                elif(value==\"\"):\n",
    "                    j=stack.pop()\n",
    "                    #print(\"j\",j)\n",
    "                    k=stack.pop()\n",
    "\n",
    "                    #print(\"k\",k)\n",
    "                    stack.append(k)\n",
    "                    stack.append(j)\n",
    "\n",
    "                    if(type(k)==type(int())):\n",
    "                        i=\"xsd:integer\"\n",
    "                    elif(type(k)==type(bool())):\n",
    "                        i=\"xsd:boolean\"\n",
    "                    elif(type(k)==type(float())) :\n",
    "                        i=\"xsd:decimal\"\n",
    "                    else:\n",
    "                        i=\"xsd:string\"\n",
    "                stack.append(i)\n",
    "\n",
    "        if type(value) == type(dict()):\n",
    "            accessJSON(value)\n",
    "        elif type(value) == type(list()):\n",
    "            c=c+1\n",
    "            if(c==2):\n",
    "                break\n",
    "            for val in value:\n",
    "                if type(val) == type(str()):\n",
    "                    pass\n",
    "                elif type(val) == type(list()):\n",
    "                    pass\n",
    "                else:\n",
    "                    accessJSON(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findingrowscolumns(keys):\n",
    "    start=''\n",
    "    ei=0\n",
    "    count = 0\n",
    "    #print(\"keysLen\",len(keys))\n",
    "    for i in range(len(keys)):\n",
    "        if(start==''):\n",
    "            start=keys[i]\n",
    "            si=0\n",
    "        elif(keys[i]==start):\n",
    "            end=keys[i-1]\n",
    "            ei=i\n",
    "            break \n",
    "        else:\n",
    "            ei=i \n",
    "\n",
    "    j=ei+1\n",
    "\n",
    "    count = 1\n",
    "    for i in range(len(keys)):\n",
    "        if(j >= len(keys)):\n",
    "            break\n",
    "        #print(\"range(EI)\",range(ei))\n",
    "        for k in range(ei):\n",
    "            #print(keys[k])\n",
    "            #print(keys[k+ei])\n",
    "            if(comparekeys(keys[k],keys[k+ei])==False):\n",
    "                print(\"Keys are not of same length\")\n",
    "        j=j+ei\n",
    "        count=count+1\n",
    "        #print(\"read \",count,\"rows\")\n",
    "\n",
    "    if(j==ei+1):\n",
    "        return count, ei+1\n",
    "    elif(ei==0):\n",
    "        return 0,0\n",
    "    else:\n",
    "        return count, ei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url regular expression\n",
    "urlRE = re.compile(r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\")\n",
    "\n",
    "#decRE = re.compile(r\"[+-]?([0-9]*[.])?[0-9]+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seperatekeyvalues(stackelements):\n",
    "    keys = []\n",
    "    values = []\n",
    "\n",
    "    for i in range(len(stackelements)):\n",
    "        if(i%2==0):\n",
    "            keys.append(stackelements[i])\n",
    "        else:\n",
    "            values.append(stackelements[i])\n",
    "    return keys, values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparekeys(w1,w2):\n",
    "    if(w1==w2):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writingintoFile(fileName, rows, column,keys, values):\n",
    "    a=np.array(values).reshape(rows, column)\n",
    "    # convert array into dataframe \n",
    "    DF = pd.DataFrame(a, columns=keys[0:column]) \n",
    "    # save the dataframe as a csv file \n",
    "    DF.to_csv(fileName,index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accessJSONLT(data):\n",
    "    global c\n",
    "    for key,value in data.items():       \n",
    "        if(type(value) == type(str()) and c==2):\n",
    "            stackLG.append(key)\n",
    "            stackLG.append(value)\n",
    "        if type(value) == type(dict()):\n",
    "            accessJSONLT(value)\n",
    "        elif type(value) == type(list()):\n",
    "            c=c+1\n",
    "            if(c == 2):\n",
    "                if(key.lower()!=\"languages\"):\n",
    "                    print(\"Error! Required language tag here!\")\n",
    "            for val in value:\n",
    "                if type(val) == type(str()):\n",
    "                    pass\n",
    "                elif type(val) == type(list()):\n",
    "                    pass\n",
    "                else:\n",
    "                    accessJSONLT(val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeDataset(f1,f2):\n",
    "    df1 = pd.read_csv(f1)\n",
    "    header1=df1.columns.tolist()\n",
    "\n",
    "    df2 = pd.read_csv(f2)\n",
    "    header2=df2.columns.tolist()\n",
    "\n",
    "    count=0\n",
    "    matchedHeader = []\n",
    "    nextHeader = []\n",
    "\n",
    "    for i in header1:\n",
    "        for j in range(len(header2)):\n",
    "            if(i==header2[j]):\n",
    "                matchedHeader.append(i)\n",
    "                count=count+1\n",
    "                nextHeader.append(header2[j+1])\n",
    "            if(count>=2):\n",
    "                break\n",
    "\n",
    "    res = df1.merge(df2, how='inner', left_on=[matchedHeader[0]], right_on=[matchedHeader[0]])\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changeLanguagetag(res):\n",
    "    lTags = pd.read_csv(\"ltgs.csv\")\n",
    "    flag=0\n",
    "    header=res.columns.tolist()\n",
    "    languagePresent = []\n",
    "\n",
    "    langColumn = \"\"\n",
    "    for i in (header):\n",
    "      if i==\"language\":\n",
    "        langcolumn = \"language\"\n",
    "        flag=1\n",
    "      elif i==\"lang\":\n",
    "        langColumn = \"lang\"\n",
    "        flag=1\n",
    "    \n",
    "    if(flag==0):\n",
    "      #print(\"returning\")\n",
    "      return res\n",
    "    \n",
    "    temp=0\n",
    "    langPresent = res[langColumn]\n",
    "    #print(newCol)\n",
    "    #languagePresent.append(res[[langColumn]])\n",
    "\n",
    "  #  print(len(res))\n",
    "    for i in range(len(langPresent)):\n",
    "        for j in range(len(lTags)):\n",
    "            if(lTags.loc[j,\"Language\"].lower() == str(langPresent[i]).lower()):\n",
    "              langPresent[i] = lTags.loc[j,\"tag\"]\n",
    "    \n",
    "    res[langColumn]=langPresent\n",
    "\n",
    "    return res\n"
   ]
  }
 ]
}